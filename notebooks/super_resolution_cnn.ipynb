{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Images Function\n",
    "def load_images(hr_path, lr_path):\n",
    "    hr_images = []\n",
    "    lr_images = []\n",
    "    \n",
    "    for i in range(1, 101):  # Assuming 100 images\n",
    "        hr_file = os.path.join(hr_path, f'HR{i:03d}.jpg')\n",
    "        lr_file = os.path.join(lr_path, f'LR{i:03d}.jpg')\n",
    "        \n",
    "        if os.path.exists(hr_file) and os.path.exists(lr_file):\n",
    "            hr_img = np.array(Image.open(hr_file).resize((256, 256))) / 255.0\n",
    "            lr_img = np.array(Image.open(lr_file).resize((64, 64))) / 255.0\n",
    "            \n",
    "            hr_images.append(hr_img)\n",
    "            lr_images.append(lr_img)\n",
    "    \n",
    "    return np.array(hr_images), np.array(lr_images)\n",
    "\n",
    "# Load the images\n",
    "hr_path = '../data/highRes'\n",
    "lr_path = '../data/lowRes'\n",
    "hr_images, lr_images = load_images(hr_path, lr_path)\n",
    "\n",
    "# Split dataset\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(\n",
    "    lr_images, hr_images, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(lr_train)}\")\n",
    "print(f\"Testing samples: {len(lr_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Build Model\n",
    "def build_sr_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, 9, padding='same', activation='relu'),\n",
    "        layers.Conv2D(32, 5, padding='same', activation='relu'),\n",
    "        layers.Conv2D(32, 5, padding='same', activation='relu'),\n",
    "        layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu'),\n",
    "        layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu'),\n",
    "        layers.Conv2D(3, 5, padding='same', activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = build_sr_model()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train Model\n",
    "history = model.fit(\n",
    "    lr_train, hr_train,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    validation_data=(lr_test, hr_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluation Function\n",
    "def evaluate_and_plot(model, lr_img, hr_img, title=\"Test Image\"):\n",
    "    sr_img = model.predict(lr_img[np.newaxis, ...])[0]\n",
    "    \n",
    "    psnr_value = psnr(hr_img, sr_img)\n",
    "    ssim_value = ssim(hr_img, sr_img, multichannel=True)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title('Low Resolution')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(hr_img)\n",
    "    plt.title('Ground Truth')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sr_img)\n",
    "    plt.title(f'Super Resolved\\nPSNR: {psnr_value:.2f}, SSIM: {ssim_value:.4f}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate Test Images\n",
    "print(\"Evaluating test images...\")\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "\n",
    "for i in range(min(5, len(lr_test))):\n",
    "    psnr_val, ssim_val = evaluate_and_plot(\n",
    "        model, lr_test[i], hr_test[i], \n",
    "        f\"Test Image {i+1}\"\n",
    "    )\n",
    "    psnr_values.append(psnr_val)\n",
    "    ssim_values.append(ssim_val)\n",
    "\n",
    "print(f\"\\nAverage PSNR: {np.mean(psnr_values):.2f} dB\")\n",
    "print(f\"Average SSIM: {np.mean(ssim_values):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
